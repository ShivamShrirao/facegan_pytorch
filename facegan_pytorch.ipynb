{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facegan_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFvHCGVA-Q6r",
        "outputId": "bc54e492-5127-48c6-8cec-f34a1b52cfb3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 11 18:57:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbF0D9-gAIUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b9902a-9c7b-4565-9438-9dfd432f1eac"
      },
      "source": [
        "%pip install -q --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110\n",
        "%pip install -q wandb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 621.4MB 27kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 13.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 66.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 57.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeQ0xHq-aqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2304c93b-29ee-4214-c999-23b1b3cc3c01"
      },
      "source": [
        "# from google.colab import files\n",
        "# ret = files.upload()\n",
        "!mkdir  ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d xhlulu/flickrfaceshq-dataset-nvidia-resized-256px\n",
        "# !kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flickrfaceshq-dataset-nvidia-resized-256px.zip to /content\n",
            "100% 1.88G/1.89G [00:30<00:00, 75.6MB/s]\n",
            "100% 1.89G/1.89G [00:30<00:00, 66.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckdwv-e_-evY"
      },
      "source": [
        "!unzip -q flickrfaceshq-dataset-nvidia-resized-256px.zip\n",
        "!rm flickrfaceshq-dataset-nvidia-resized-256px.zip\n",
        "# !unzip -q celeba-dataset.zip\n",
        "# !rm celeba-dataset.zip"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7uNrMo-S8T"
      },
      "source": [
        "!mkdir flickrface_dataset\n",
        "!mv resized flickrface_dataset/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHqEBieBjlH"
      },
      "source": [
        "DATA_DIR = \"/content/flickrface_dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dU-VM_CG9Km"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLkIHo4R-gip"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ-IGTrx-ova"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "from torch.cuda import amp\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import PIL.Image as Image\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.facecolor'] = 'white'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_athS9wr4Lu"
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGM0uvd9r42K"
      },
      "source": [
        "config_defaults = {\n",
        "    'BATCH_SIZE'        : 128,\n",
        "    'noise_dim'         : 128,\n",
        "    'input_size'        : 256,\n",
        "    'dp_rate'           : 0.3,\n",
        "    'gauss_std'         : 0.1,\n",
        "    'std_decay_rate'    : 0.,#1/100,  # DO VERIFY\n",
        "    'guassian_noise'    : ['discriminator'],\n",
        "    'nthreads'          : 2 * len(os.sched_getaffinity(0)),\n",
        "    'max_lr'            : 2e-4,\n",
        "    'betas'             : (0.5, 0.999),\n",
        "    'seed'              : 614,\n",
        "    'use_amp'           : True,\n",
        "    'log_interval'      : 10,\n",
        "    \"z_notes\"           : []\n",
        "}\n",
        "CONFIG = config_defaults"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruN404CCr5PM"
      },
      "source": [
        "# #hide\n",
        "# run = wandb.init(id='19sqz0by', project=\"facegan_pytorch\", resume='must')\n",
        "# CONFIG = run.config"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R83YKK2hr84h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7ea2a618-737a-4f3d-b8b1-6d73c78af005"
      },
      "source": [
        "run = wandb.init(project=\"facegan_pytorch\", config=config_defaults)\n",
        "CONFIG = wandb.config"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivamshrirao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">firm-music-31</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/shivamshrirao/facegan_pytorch\" target=\"_blank\">https://wandb.ai/shivamshrirao/facegan_pytorch</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/shivamshrirao/facegan_pytorch/runs/1424g5hk\" target=\"_blank\">https://wandb.ai/shivamshrirao/facegan_pytorch/runs/1424g5hk</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210711_191156-1424g5hk</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIxwyb-3-5Hs"
      },
      "source": [
        "def seed_everything(seed=33):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljk8xCMBDIOp"
      },
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self, name=None):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = self.sum = self.count = self.avg = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNMFa5ke_85-"
      },
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "from nvidia.dali.pipeline import Pipeline\n",
        "import nvidia.dali.fn as fn\n",
        "import nvidia.dali.types as types\n",
        "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI_oNKS4_6yv"
      },
      "source": [
        "def get_preproc(input_size):\n",
        "    return T.Compose([\n",
        "        T.RandomResizedCrop(input_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.RandomHorizontalFlip(input_size),\n",
        "        lambda image: image.convert(\"RGB\"),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "\n",
        "\n",
        "def dali_pipeline(batch_size, num_threads, device_id, image_dir, input_size):\n",
        "    pipe = Pipeline(batch_size, num_threads, device_id)\n",
        "    with pipe:\n",
        "        jpegs, lbls = fn.readers.file(file_root=image_dir, random_shuffle=True, name=\"Reader\")\n",
        "        images = fn.decoders.image(jpegs, device='mixed', output_type=types.RGB)\n",
        "        images = fn.resize(images, device='gpu', resize_shorter=input_size, interp_type=types.INTERP_TRIANGULAR)\n",
        "        mirror = fn.random.coin_flip(probability=0.5)\n",
        "        images = fn.crop_mirror_normalize(images,\n",
        "                                          dtype=types.FLOAT,\n",
        "                                          output_layout=\"CHW\",\n",
        "                                          crop=(input_size, input_size),\n",
        "                                          mean=[0.5 * 255, 0.5 * 255, 0.5 * 255],\n",
        "                                          std=[0.5 * 255, 0.5 * 255, 0.5 * 255],\n",
        "                                          mirror=mirror)\n",
        "        pipe.set_outputs(images, lbls)\n",
        "    return pipe"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j3JDXBazj6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a99ec4-446b-478d-ce54-465901e71286"
      },
      "source": [
        "CONFIG['nthreads']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je-jAyqkAVr8"
      },
      "source": [
        "pipe = dali_pipeline(batch_size=CONFIG['BATCH_SIZE'], num_threads=CONFIG[\"nthreads\"], device_id=0, image_dir=DATA_DIR, input_size=CONFIG[\"input_size\"])\n",
        "train_loader = DALIClassificationIterator(pipe, auto_reset=True, reader_name=\"Reader\", last_batch_policy=LastBatchPolicy.PARTIAL)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8RpgGza_RZY"
      },
      "source": [
        "class GaussianNoise(nn.Module):                         # Try noise just for real or just for fake images.\n",
        "    def __init__(self, std=0.1, decay_rate=0):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.decay_rate = decay_rate\n",
        "\n",
        "    def decay_step(self):\n",
        "        self.std = max(self.std - self.decay_rate, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            return x + torch.empty_like(x).normal_(std=self.std)\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLQY0yib_SEf"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, activation=nn.LeakyReLU, dp_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.stem = nn.Sequential(OrderedDict([\n",
        "            ('linear',  nn.Linear(noise_dim, 1024*4*4, bias=False)),            # remove this, replace with just conv\n",
        "            ('bn',      nn.LazyBatchNorm1d()),\n",
        "            ('act',     activation(0.2, inplace=True)),\n",
        "            ('dropout', nn.Dropout(dp_rate)),       # try 2d for spatial\n",
        "        ]))\n",
        "\n",
        "        self.stacks = nn.Sequential(*[\n",
        "            self.upsample(512, dp_rate=dp_rate),\n",
        "            self.upsample(256, dp_rate=dp_rate),\n",
        "            self.upsample(128, dp_rate=dp_rate),\n",
        "            self.upsample( 64, dp_rate=dp_rate),\n",
        "            self.upsample( 32, dp_rate=0)           # add one more with stride 1\n",
        "        ])\n",
        "\n",
        "        self.gen = nn.Sequential(OrderedDict([\n",
        "            ('conv',    nn.LazyConvTranspose2d(3, kernel_size=4, stride=2, padding=1)),\n",
        "            ('act',     nn.Tanh()),\n",
        "        ]))\n",
        "\n",
        "    def upsample(self, num_filters, bn=True, dp_rate=0.3):\n",
        "        layers = [nn.LazyConvTranspose2d(num_filters, kernel_size=4, stride=2, bias=not bn, padding=1)]\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(num_filters))\n",
        "        layers.append(self.activation(0.2, inplace=True))\n",
        "        if dp_rate > 0:\n",
        "            layers.append(nn.Dropout2d(dp_rate))      # try 2d for spatial\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = x.view(-1, 1024, 4, 4)\n",
        "        x = self.stacks(x)\n",
        "        x = self.gen(x)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJPshbl_VF6"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, activation=nn.LeakyReLU, std=0.1, std_decay_rate=0):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.std_decay_rate = std_decay_rate\n",
        "        self.activation = activation\n",
        "        self.stacks = nn.Sequential(*[\n",
        "            self.downsample(32, bn=False),\n",
        "            self.downsample(64),\n",
        "            self.downsample(128),\n",
        "            self.downsample(256),\n",
        "            self.downsample(512),\n",
        "            self.downsample(1024),\n",
        "        ])\n",
        "\n",
        "        self.head = nn.Sequential(OrderedDict([\n",
        "            ('gauss', GaussianNoise(self.std, self.std_decay_rate)),\n",
        "            ('linear', nn.LazyLinear(1)),\n",
        "            # ('act', nn.Sigmoid()),        # removed for BCEWithLogitsLoss\n",
        "        ]))\n",
        "\n",
        "    def downsample(self, num_filters, bn=True, stride=2):\n",
        "        layers = [\n",
        "            GaussianNoise(self.std, self.std_decay_rate),\n",
        "            nn.LazyConv2d(num_filters, kernel_size=4, stride=stride, bias=not bn, padding=1)\n",
        "        ]\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(num_filters))\n",
        "        layers.append(self.activation(0.2, inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stacks(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEvizYK2_Amq"
      },
      "source": [
        "@torch.no_grad()\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoVawbzC_Xcb"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbuK7xPs_ci8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9a65d3-8a45-480a-cf11-83e22a733528"
      },
      "source": [
        "netG = Generator(CONFIG['noise_dim'], dp_rate=CONFIG['dp_rate']).to(DEVICE)\n",
        "netD = Discriminator(std=CONFIG['gauss_std'], std_decay_rate=CONFIG['std_decay_rate']).to(DEVICE)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS53p7J0vOQE"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pq4ymKzvq1E",
        "outputId": "822f0139-21bb-40c4-a010-62bf2f380ea5"
      },
      "source": [
        "summary(netG, (CONFIG['noise_dim'],))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 16384]       2,097,152\n",
            "       BatchNorm1d-2                [-1, 16384]          32,768\n",
            "              ReLU-3                [-1, 16384]               0\n",
            "           Dropout-4                [-1, 16384]               0\n",
            "   ConvTranspose2d-5            [-1, 512, 8, 8]       8,388,608\n",
            "       BatchNorm2d-6            [-1, 512, 8, 8]           1,024\n",
            "              ReLU-7            [-1, 512, 8, 8]               0\n",
            "         Dropout2d-8            [-1, 512, 8, 8]               0\n",
            "   ConvTranspose2d-9          [-1, 256, 16, 16]       2,097,152\n",
            "      BatchNorm2d-10          [-1, 256, 16, 16]             512\n",
            "             ReLU-11          [-1, 256, 16, 16]               0\n",
            "        Dropout2d-12          [-1, 256, 16, 16]               0\n",
            "  ConvTranspose2d-13          [-1, 128, 32, 32]         524,288\n",
            "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
            "             ReLU-15          [-1, 128, 32, 32]               0\n",
            "        Dropout2d-16          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-17           [-1, 64, 64, 64]         131,072\n",
            "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
            "             ReLU-19           [-1, 64, 64, 64]               0\n",
            "        Dropout2d-20           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-21         [-1, 32, 128, 128]          32,768\n",
            "      BatchNorm2d-22         [-1, 32, 128, 128]              64\n",
            "             ReLU-23         [-1, 32, 128, 128]               0\n",
            "  ConvTranspose2d-24          [-1, 3, 256, 256]           1,539\n",
            "             Tanh-25          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 13,307,331\n",
            "Trainable params: 13,307,331\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 30.50\n",
            "Params size (MB): 50.76\n",
            "Estimated Total Size (MB): 81.26\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oea3QscrvrHJ",
        "outputId": "39323866-ab9a-4479-ef7e-b25f54c5c0d7"
      },
      "source": [
        "summary(netD, (3, CONFIG['input_size'], CONFIG['input_size']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "     GaussianNoise-1          [-1, 3, 256, 256]               0\n",
            "            Conv2d-2         [-1, 32, 128, 128]           1,568\n",
            "         LeakyReLU-3         [-1, 32, 128, 128]               0\n",
            "     GaussianNoise-4         [-1, 32, 128, 128]               0\n",
            "            Conv2d-5           [-1, 64, 64, 64]          32,768\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "         LeakyReLU-7           [-1, 64, 64, 64]               0\n",
            "     GaussianNoise-8           [-1, 64, 64, 64]               0\n",
            "            Conv2d-9          [-1, 128, 32, 32]         131,072\n",
            "      BatchNorm2d-10          [-1, 128, 32, 32]             256\n",
            "        LeakyReLU-11          [-1, 128, 32, 32]               0\n",
            "    GaussianNoise-12          [-1, 128, 32, 32]               0\n",
            "           Conv2d-13          [-1, 256, 16, 16]         524,288\n",
            "      BatchNorm2d-14          [-1, 256, 16, 16]             512\n",
            "        LeakyReLU-15          [-1, 256, 16, 16]               0\n",
            "    GaussianNoise-16          [-1, 256, 16, 16]               0\n",
            "           Conv2d-17            [-1, 512, 8, 8]       2,097,152\n",
            "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-19            [-1, 512, 8, 8]               0\n",
            "    GaussianNoise-20            [-1, 512, 8, 8]               0\n",
            "           Conv2d-21           [-1, 1024, 4, 4]       8,388,608\n",
            "      BatchNorm2d-22           [-1, 1024, 4, 4]           2,048\n",
            "        LeakyReLU-23           [-1, 1024, 4, 4]               0\n",
            "    GaussianNoise-24                [-1, 16384]               0\n",
            "           Linear-25                    [-1, 1]          16,385\n",
            "================================================================\n",
            "Total params: 11,195,809\n",
            "Trainable params: 11,195,809\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 29.00\n",
            "Params size (MB): 42.71\n",
            "Estimated Total Size (MB): 72.46\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9GGI5_x0v4f",
        "outputId": "267db350-37bb-4028-ec4e-7f3ab78ae57f"
      },
      "source": [
        "wandb.watch([netG, netD], log=None)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f000586ed90>,\n",
              " <wandb.wandb_torch.TorchGraph at 0x7f00592b72d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjgGrKRb_h3z"
      },
      "source": [
        "optG = torch.optim.Adam(netG.parameters(), lr=CONFIG['max_lr'], betas=CONFIG['betas'])\n",
        "optD = torch.optim.Adam(netD.parameters(), lr=CONFIG['max_lr'], betas=CONFIG['betas'])\n",
        "\n",
        "scaler = amp.GradScaler(enabled=CONFIG['use_amp'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFNXRm2mkkKC"
      },
      "source": [
        "def set_grads(grads, params):\n",
        "    for g,p in zip(grads, params):\n",
        "        p.grad = g\n",
        "\n",
        "def train_epoch(train_loader, netG, netD, optG, optD, scaler, noise_dim, epoch=1, use_amp=True, log_interval=10):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    lossesG = AverageMeter()\n",
        "    lossesD = AverageMeter()\n",
        "    optG.zero_grad(set_to_none=True)\n",
        "    optD.zero_grad(set_to_none=True)\n",
        "    with tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch:>2}\") as pbar:\n",
        "        for idx, batch in pbar:\n",
        "            real_images = batch[0]['data']\n",
        "            noise = torch.randn(real_images.size(0), noise_dim, dtype=real_images.dtype,\n",
        "                                device=real_images.device)\n",
        "            with amp.autocast(enabled=use_amp):\n",
        "                fake_out = netD(netG(noise))\n",
        "                real_out = netD(real_images)\n",
        "                lossG = criterion(fake_out, torch.ones_like(fake_out))                          # Treat fake images as real to train the Generator.\n",
        "                lossD = (criterion(real_out, torch.empty_like(real_out).uniform_(0.9, 1.0))     # Treat real as real\n",
        "                        + criterion(fake_out, torch.empty_like(fake_out).uniform_(0.0, 0.1)))   # and fake as fake to train Discriminator.\n",
        "\n",
        "            scaled_gradsG = autograd.grad(scaler.scale(lossG), netG.parameters(), retain_graph=True)\n",
        "            scaled_gradsD = autograd.grad(scaler.scale(lossD), netD.parameters())\n",
        "\n",
        "            set_grads(scaled_gradsG, netG.parameters())\n",
        "            set_grads(scaled_gradsD, netD.parameters())\n",
        "\n",
        "            scaler.step(optD)\n",
        "            optD.zero_grad(set_to_none=True)\n",
        "            scaler.step(optG)\n",
        "            optG.zero_grad(set_to_none=True)\n",
        "            scaler.update()\n",
        "\n",
        "            lossesG.update(lossG.detach_(), noise.size(0))\n",
        "            lossesD.update(lossD.detach_(), real_images.size(0))\n",
        "            if not idx%log_interval:\n",
        "                info = {'Generator_loss': float(lossesG.avg), 'Discriminator_loss': float(lossesD.avg)}\n",
        "                wandb.log(info)\n",
        "                pbar.set_postfix(info)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1I1o5j43nYo"
      },
      "source": [
        "@torch.no_grad()\n",
        "def gen_grid(ncols=4, nrows=4, figsize=[16,16], show=True, wb_log=True):\n",
        "    netG.eval()\n",
        "    noise = torch.randn(nrows*ncols, CONFIG['noise_dim'], dtype=torch.float32, device=DEVICE)\n",
        "    gen = (netG(noise).detach_()+1)/2\n",
        "    gen = gen.cpu().permute(0,2,3,1).numpy()       # convert to channel last\n",
        "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "    fig.patch.set_facecolor('black')\n",
        "    ims = []\n",
        "    for i,axi in enumerate(ax.flat):\n",
        "        axi.axis(\"off\")\n",
        "        axi.imshow(gen[i])\n",
        "        if wb_log: ims.append(wandb.Image(gen[i]))\n",
        "    if wb_log: wandb.log({\"Generated\": ims})\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close(fig)\n",
        "    # return gen"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzLeJBR-HO_"
      },
      "source": [
        "def decay_gauss_std(net):\n",
        "    std = 0\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, GaussianNoise):\n",
        "            m.decay_step()\n",
        "            std = m.std\n",
        "    wandb.log({'std': std})"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-a9W4aNE3Nl"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg5FUdDNE2CT"
      },
      "source": [
        "init_epoch = 1\n",
        "NUM_EPOCHS = 200"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHNHYmqjavTK",
        "outputId": "2c69d484-135e-4f0f-9071-005e8525aa17"
      },
      "source": [
        "#collapse-output\n",
        "for epoch in range(init_epoch, NUM_EPOCHS+1):\n",
        "    train_loss = train_epoch(train_loader,\n",
        "                             netG = netG,\n",
        "                             netD = netD,\n",
        "                             optG = optG,\n",
        "                             optD = optD,\n",
        "                             scaler = scaler,\n",
        "                             noise_dim = CONFIG['noise_dim'],\n",
        "                             epoch=epoch,\n",
        "                             use_amp=CONFIG['use_amp'],\n",
        "                             log_interval=CONFIG['log_interval'])\n",
        "    \n",
        "    gen_grid(ncols=4, nrows=2, figsize=[16, 8], show=False)\n",
        "    gc.collect()\n",
        "    decay_gauss_std(netD)\n",
        "    # if not epoch%20:\n",
        "    #     gen_grid(wb_log=False)\n",
        "    #     save_model(model, optimizer, epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1: 100%|██████████| 547/547 [01:03<00:00,  8.64it/s, Generator_loss=2.89, Discriminator_loss=0.729]\n",
            "Epoch  2: 100%|██████████| 547/547 [01:02<00:00,  8.78it/s, Generator_loss=2.3, Discriminator_loss=0.811]\n",
            "Epoch  3: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.42, Discriminator_loss=0.716]\n",
            "Epoch  4: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.6, Discriminator_loss=0.669]\n",
            "Epoch  5: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.73, Discriminator_loss=0.668]\n",
            "Epoch  6: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=2.81, Discriminator_loss=0.622]\n",
            "Epoch  7: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.79, Discriminator_loss=0.62]\n",
            "Epoch  8: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.91, Discriminator_loss=0.594]\n",
            "Epoch  9: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=2.95, Discriminator_loss=0.576]\n",
            "Epoch 10: 100%|██████████| 547/547 [01:02<00:00,  8.77it/s, Generator_loss=2.97, Discriminator_loss=0.555]\n",
            "Epoch 11: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.91, Discriminator_loss=0.572]\n",
            "Epoch 12: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=2.93, Discriminator_loss=0.544]\n",
            "Epoch 13: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.99, Discriminator_loss=0.557]\n",
            "Epoch 14: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=2.86, Discriminator_loss=0.565]\n",
            "Epoch 15: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=3, Discriminator_loss=0.524]\n",
            "Epoch 16: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.89, Discriminator_loss=0.524]\n",
            "Epoch 17: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=2.93, Discriminator_loss=0.552]\n",
            "Epoch 18: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.91, Discriminator_loss=0.573]\n",
            "Epoch 19: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.84, Discriminator_loss=0.555]\n",
            "Epoch 20: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.88, Discriminator_loss=0.508]\n",
            "Epoch 21: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=2.86, Discriminator_loss=0.576]\n",
            "Epoch 22: 100%|██████████| 547/547 [01:01<00:00,  8.88it/s, Generator_loss=2.94, Discriminator_loss=0.518]\n",
            "Epoch 23: 100%|██████████| 547/547 [01:01<00:00,  8.88it/s, Generator_loss=2.94, Discriminator_loss=0.506]\n",
            "Epoch 24: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=2.9, Discriminator_loss=0.552]\n",
            "Epoch 25: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.97, Discriminator_loss=0.504]\n",
            "Epoch 26: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.9, Discriminator_loss=0.508]\n",
            "Epoch 27: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.86, Discriminator_loss=0.551]\n",
            "Epoch 28: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.96, Discriminator_loss=0.513]\n",
            "Epoch 29: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.96, Discriminator_loss=0.511]\n",
            "Epoch 30: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=3.04, Discriminator_loss=0.488]\n",
            "Epoch 31: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=2.83, Discriminator_loss=0.524]\n",
            "Epoch 32: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=3.05, Discriminator_loss=0.454]\n",
            "Epoch 33: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.97, Discriminator_loss=0.506]\n",
            "Epoch 34: 100%|██████████| 547/547 [01:02<00:00,  8.75it/s, Generator_loss=2.94, Discriminator_loss=0.549]\n",
            "Epoch 35: 100%|██████████| 547/547 [01:02<00:00,  8.74it/s, Generator_loss=2.99, Discriminator_loss=0.489]\n",
            "Epoch 36: 100%|██████████| 547/547 [01:02<00:00,  8.78it/s, Generator_loss=3.05, Discriminator_loss=0.448]\n",
            "Epoch 37: 100%|██████████| 547/547 [01:02<00:00,  8.75it/s, Generator_loss=2.95, Discriminator_loss=0.524]\n",
            "Epoch 38: 100%|██████████| 547/547 [01:02<00:00,  8.74it/s, Generator_loss=3.01, Discriminator_loss=0.487]\n",
            "Epoch 39: 100%|██████████| 547/547 [01:02<00:00,  8.73it/s, Generator_loss=2.99, Discriminator_loss=0.508]\n",
            "Epoch 40: 100%|██████████| 547/547 [01:02<00:00,  8.70it/s, Generator_loss=3.02, Discriminator_loss=0.513]\n",
            "Epoch 41: 100%|██████████| 547/547 [01:02<00:00,  8.74it/s, Generator_loss=2.97, Discriminator_loss=0.451]\n",
            "Epoch 42: 100%|██████████| 547/547 [01:02<00:00,  8.74it/s, Generator_loss=3.06, Discriminator_loss=0.498]\n",
            "Epoch 43: 100%|██████████| 547/547 [01:02<00:00,  8.73it/s, Generator_loss=3.01, Discriminator_loss=0.466]\n",
            "Epoch 44: 100%|██████████| 547/547 [01:02<00:00,  8.72it/s, Generator_loss=3.01, Discriminator_loss=0.485]\n",
            "Epoch 45: 100%|██████████| 547/547 [01:02<00:00,  8.76it/s, Generator_loss=3.01, Discriminator_loss=0.484]\n",
            "Epoch 46: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=3.09, Discriminator_loss=0.446]\n",
            "Epoch 47: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.78, Discriminator_loss=0.611]\n",
            "Epoch 48: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=2.99, Discriminator_loss=0.478]\n",
            "Epoch 49: 100%|██████████| 547/547 [01:01<00:00,  8.84it/s, Generator_loss=3.04, Discriminator_loss=0.44]\n",
            "Epoch 50: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.94, Discriminator_loss=0.52]\n",
            "Epoch 51: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=3.03, Discriminator_loss=0.458]\n",
            "Epoch 52: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.97, Discriminator_loss=0.503]\n",
            "Epoch 53: 100%|██████████| 547/547 [01:02<00:00,  8.78it/s, Generator_loss=3.03, Discriminator_loss=0.456]\n",
            "Epoch 54: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=3.07, Discriminator_loss=0.44]\n",
            "Epoch 55: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=2.7, Discriminator_loss=0.637]\n",
            "Epoch 56: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=2.95, Discriminator_loss=0.465]\n",
            "Epoch 57: 100%|██████████| 547/547 [01:01<00:00,  8.85it/s, Generator_loss=3.08, Discriminator_loss=0.442]\n",
            "Epoch 58: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=3.06, Discriminator_loss=0.463]\n",
            "Epoch 59: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=3.04, Discriminator_loss=0.504]\n",
            "Epoch 60: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.96, Discriminator_loss=0.464]\n",
            "Epoch 61: 100%|██████████| 547/547 [01:01<00:00,  8.83it/s, Generator_loss=3.09, Discriminator_loss=0.436]\n",
            "Epoch 62: 100%|██████████| 547/547 [01:02<00:00,  8.77it/s, Generator_loss=3.02, Discriminator_loss=0.478]\n",
            "Epoch 63: 100%|██████████| 547/547 [01:02<00:00,  8.75it/s, Generator_loss=3.02, Discriminator_loss=0.476]\n",
            "Epoch 64: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=3.08, Discriminator_loss=0.434]\n",
            "Epoch 65: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=3.1, Discriminator_loss=0.445]\n",
            "Epoch 66: 100%|██████████| 547/547 [01:02<00:00,  8.78it/s, Generator_loss=2.9, Discriminator_loss=0.528]\n",
            "Epoch 67: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=3.08, Discriminator_loss=0.437]\n",
            "Epoch 68: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.98, Discriminator_loss=0.493]\n",
            "Epoch 69: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=3.05, Discriminator_loss=0.479]\n",
            "Epoch 70: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=2.95, Discriminator_loss=0.455]\n",
            "Epoch 71: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=3.08, Discriminator_loss=0.431]\n",
            "Epoch 72: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=3.09, Discriminator_loss=0.43]\n",
            "Epoch 73: 100%|██████████| 547/547 [01:02<00:00,  8.80it/s, Generator_loss=2.98, Discriminator_loss=0.5]\n",
            "Epoch 74: 100%|██████████| 547/547 [01:02<00:00,  8.82it/s, Generator_loss=3.05, Discriminator_loss=0.466]\n",
            "Epoch 75: 100%|██████████| 547/547 [01:01<00:00,  8.85it/s, Generator_loss=3.06, Discriminator_loss=0.434]\n",
            "Epoch 76: 100%|██████████| 547/547 [01:01<00:00,  8.87it/s, Generator_loss=3.1, Discriminator_loss=0.433]\n",
            "Epoch 77: 100%|██████████| 547/547 [01:01<00:00,  8.86it/s, Generator_loss=3.04, Discriminator_loss=0.47]\n",
            "Epoch 78: 100%|██████████| 547/547 [01:02<00:00,  8.81it/s, Generator_loss=3.06, Discriminator_loss=0.469]\n",
            "Epoch 79: 100%|██████████| 547/547 [01:02<00:00,  8.77it/s, Generator_loss=3.06, Discriminator_loss=0.435]\n",
            "Epoch 80: 100%|██████████| 547/547 [01:02<00:00,  8.78it/s, Generator_loss=3.09, Discriminator_loss=0.426]\n",
            "Epoch 81: 100%|██████████| 547/547 [01:02<00:00,  8.77it/s, Generator_loss=3.04, Discriminator_loss=0.476]\n",
            "Epoch 82: 100%|██████████| 547/547 [01:02<00:00,  8.79it/s, Generator_loss=3.08, Discriminator_loss=0.428]\n",
            "Epoch 83:  70%|███████   | 384/547 [00:43<00:18,  8.65it/s, Generator_loss=2.94, Discriminator_loss=0.526]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY9tw0_XazXr"
      },
      "source": [
        "_ = gen_grid(wb_log=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riXWwDCxZPD8"
      },
      "source": [
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmAXNzkcBFb-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}